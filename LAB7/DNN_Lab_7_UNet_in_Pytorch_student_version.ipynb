{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqQZ0FqJ8zHY"
   },
   "source": [
    "Code based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "In this exercise, we are going to implement a [UNet-like](https://arxiv.org/pdf/1505.04597.pdf) architecture for the semantic segmentation task. \n",
    "The model is trained on the [Pascal VOC](https://paperswithcode.github.io/torchbench/pascalvoc/) dataset.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "    1. Implement the missing pieces in the code.\n",
    "\n",
    "    2. Check that the given implementation reaches 68% test accuracy after a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "QfIXmJ-dRXfE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "FxGS_WsORXfF"
   },
   "outputs": [],
   "source": [
    "class UNetConvolutionStack(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNetConvolutionStack, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "lyN2g-yQRXfG"
   },
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, first_layer=False):\n",
    "        super(EncoderStack, self).__init__()\n",
    "        if first_layer:\n",
    "            self.down = nn.Sequential(\n",
    "                UNetConvolutionStack(in_channel, out_channel),\n",
    "                UNetConvolutionStack(out_channel, out_channel),\n",
    "            )\n",
    "        else:\n",
    "            self.down = nn.Sequential(\n",
    "                nn.MaxPool2d((2, 2)),\n",
    "                UNetConvolutionStack(in_channel, out_channel),\n",
    "                UNetConvolutionStack(out_channel, out_channel),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "dp2-OwXORXfG"
   },
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(\n",
    "            in_channel, in_channel, 3, stride=2, padding=1\n",
    "        )\n",
    "        self.up = nn.Sequential(\n",
    "            UNetConvolutionStack(in_channel + out_channel, out_channel),\n",
    "            UNetConvolutionStack(out_channel, out_channel),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # TODO: implement skipconnections.\n",
    "        # hint: x is the output of previous decoder layer,\n",
    "        # y is the output of corresponding encoder layer.\n",
    "        # Based on the arguments of the constructor,\n",
    "        # how should x and y be combined?\n",
    "        x = self.upsample(x, output_size=y.shape)\n",
    "        xy = torch.cat((x, y), dim=1)\n",
    "        xy = self.up(xy)\n",
    "        \n",
    "        return xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "RBPeqMNSRXfG"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoder_channels, decoder_channels, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.decoder = nn.ModuleList()\n",
    "        self.conv = nn.Conv2d(\n",
    "            decoder_channels[-1], num_classes, kernel_size=3, padding=1\n",
    "        )\n",
    "\n",
    "        encoder_sizes = zip(\n",
    "            range(len(encoder_channels)), encoder_channels, encoder_channels[1:]\n",
    "        )\n",
    "        for idx, in_size, out_size in encoder_sizes:\n",
    "            if idx > 0:\n",
    "                self.encoder.append(EncoderStack(in_size, out_size))\n",
    "            else:\n",
    "                self.encoder.append(EncoderStack(in_size, out_size, first_layer=True))\n",
    "\n",
    "        decoder_sizes = zip(decoder_channels, decoder_channels[1:])\n",
    "        for in_size, out_size in decoder_sizes:\n",
    "            self.decoder.append(DecoderStack(in_size, out_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: implement UNet's forward pass.\n",
    "        # hint: Remeber to store outputs of subsequent\n",
    "        # encoder layers to use as input to decoer layers!\n",
    "        # Do not forget about the final convolution.\n",
    "        encoder_outputs = []\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            encoder_outputs.append(x)\n",
    "        encoder_outputs.pop()\n",
    "        encoder_outputs.reverse()\n",
    "        for layer, output in zip(self.decoder, encoder_outputs):\n",
    "            x = layer(x, output)\n",
    "        x = self.conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "5AKH3oUqRXfH"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    _, _, image_width, image_height = data.size()\n",
    "    test_loss /= len(test_loader.dataset) * image_width * image_height\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            (len(test_loader.dataset) * image_width * image_height),\n",
    "            100.0 * correct / (len(test_loader.dataset) * image_width * image_height),\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "Ed1Rwhv-RXfH"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_batch_size = 1000\n",
    "epochs = 5\n",
    "lr = 1e-2\n",
    "use_cuda = True\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "num_classes = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "Ht3SPPVlRXfH"
   },
   "outputs": [],
   "source": [
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "use_mps = torch.backends.mps.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "\n",
    "train_kwargs = {\"batch_size\": batch_size}\n",
    "test_kwargs = {\"batch_size\": test_batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {\"num_workers\": 1, \"pin_memory\": True, \"shuffle\": True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dD85qSzwRXfI"
   },
   "outputs": [],
   "source": [
    "def replace_tensor_value_(tensor, a, b):\n",
    "    tensor[tensor == a] = b\n",
    "    return tensor\n",
    "\n",
    "\n",
    "input_resize = transforms.Resize((224, 224))\n",
    "input_transform = transforms.Compose(\n",
    "    [\n",
    "        input_resize,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "target_resize = transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST)\n",
    "target_transform = transforms.Compose(\n",
    "    [\n",
    "        target_resize,\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.Lambda(\n",
    "            lambda x: replace_tensor_value_(x.squeeze(0).long(), 255, 21)\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "y7r9wpzeRXfI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ../data/VOCtrainval_11-May-2012.tar\n",
      "Extracting ../data/VOCtrainval_11-May-2012.tar to ../data\n",
      "Using downloaded and verified file: ../data/VOCtrainval_11-May-2012.tar\n",
      "Extracting ../data/VOCtrainval_11-May-2012.tar to ../data\n"
     ]
    }
   ],
   "source": [
    "dataset1 = datasets.VOCSegmentation(\n",
    "    \"../data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "dataset2 = datasets.VOCSegmentation(\n",
    "    \"../data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **train_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "C1KtqXIPRXfJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:37, 37.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1464 (0%)]\tLoss: -0.084607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [02:27,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/1464 (83%)]\tLoss: -4.048810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [02:28, 12.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -5.1137, Accuracy: 2819245/72705024 (4%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/1464 (0%)]\tLoss: -5.114265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:43,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [1280/1464 (83%)]\tLoss: -11.375424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:43,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -15.0414, Accuracy: 34282713/72705024 (47%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [0/1464 (0%)]\tLoss: -12.953732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:29,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [1280/1464 (83%)]\tLoss: -21.911077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:30,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -24.2186, Accuracy: 44734704/72705024 (62%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0/1464 (0%)]\tLoss: -24.150335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:41,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [1280/1464 (83%)]\tLoss: -36.481316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:42,  3.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -38.9215, Accuracy: 50208922/72705024 (69%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/1464 (0%)]\tLoss: -39.528728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:30,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [1280/1464 (83%)]\tLoss: -55.245201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:31,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -87.0827, Accuracy: 48087158/72705024 (66%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = UNet(\n",
    "    encoder_channels=[3, 8, 16, 32],\n",
    "    decoder_channels=[32, 16, 8],\n",
    "    num_classes=num_classes,\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "    test(model, device, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GifpCp-rRXfJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2Aa03GTRXfJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6fa2fa4f4d9d3d9ca73eb3739cc0e85a72773041ed8c7376d5dc2c41e6946bf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
